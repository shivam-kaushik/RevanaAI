{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzwbZMwVywpC",
        "outputId": "d31b568e-91b4-458a-ea78-e1278dab0cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Chunk 1] wrote 150,067 rows\n",
            "[Chunk 2] wrote 149,848 rows\n",
            "[Chunk 3] wrote 149,642 rows\n",
            "[Chunk 4] wrote 150,317 rows\n",
            "[Chunk 5] wrote 150,228 rows\n",
            "[Chunk 6] wrote 149,846 rows\n",
            "[Chunk 7] wrote 149,758 rows\n",
            "[Chunk 8] wrote 150,329 rows\n",
            "[Chunk 9] wrote 150,675 rows\n",
            "[Chunk 10] wrote 149,657 rows\n",
            "[Chunk 11] wrote 150,055 rows\n",
            "[Chunk 12] wrote 149,705 rows\n",
            "[Chunk 13] wrote 150,071 rows\n",
            "[Chunk 14] wrote 150,440 rows\n",
            "[Chunk 15] wrote 150,326 rows\n",
            "[Chunk 16] wrote 150,056 rows\n",
            "[Chunk 17] wrote 149,482 rows\n",
            "[Chunk 18] wrote 149,716 rows\n",
            "[Chunk 19] wrote 150,152 rows\n",
            "[Chunk 20] wrote 149,973 rows\n",
            "\n",
            "Done. Files written:\n",
            "  - retail_clean_full_exploded_categorized_FINAL.csv\n",
            "  - product_to_category_mapping_FINAL.csv\n",
            "  - uncertain_products_FINAL.csv (should be empty)\n",
            "\n",
            "Category breakdown (unique products):\n",
            "product_category\n",
            "Household               21\n",
            "Pantry/Condiments       11\n",
            "Personal Care           10\n",
            "Produce                  8\n",
            "Home & Garden            6\n",
            "Dairy                    6\n",
            "Beverages                4\n",
            "Electronics/Hardware     3\n",
            "Seafood                  3\n",
            "Baby                     2\n",
            "Bakery                   2\n",
            "Meat                     2\n",
            "Breakfast & Cereal       2\n",
            "Snacks                   1\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Robust, precedence-aware product categorizer for\n",
        "    Retail_Transactions_Dataset.csv\n",
        "\n",
        "It:\n",
        "  1) Parses list-like product cells into individual items\n",
        "  2) Cleans display names (title-case, whitespace)\n",
        "  3) Categorizes via layered rules:\n",
        "        exact  -> phrase  -> token families  -> head-noun heuristics\n",
        "  4) Asserts zero \"Other/fallback\" remain\n",
        "  5) Saves:\n",
        "        - retail_clean_full_exploded_categorized_FINAL.csv\n",
        "        - product_to_category_mapping_FINAL.csv\n",
        "        - uncertain_products_FINAL.csv (should end up empty)\n",
        "\n",
        "Tune EXACT_MAP or FAMILY_KEYWORDS to your taste; they’re already expanded\n",
        "to cover the misses you showed (broom, cereal, toothbrush, salmon, etc.).\n",
        "\"\"\"\n",
        "\n",
        "import ast\n",
        "import re\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Tuple, Dict\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ---------- Paths ----------\n",
        "INPUT  = Path(\"Retail_Transactions_Dataset (1).csv\")\n",
        "OUTPUT = Path(\"retail_clean_full_exploded_categorized_FINAL.csv\")\n",
        "MAPCSV = Path(\"product_to_category_mapping_FINAL.csv\")\n",
        "UNCERT = Path(\"uncertain_products_FINAL.csv\")\n",
        "\n",
        "CHUNK_SIZE = 50000\n",
        "\n",
        "PRODUCT_COL_CANDIDATES = {\"customer_product\", \"product\", \"products\", \"product_list\", \"items\"}\n",
        "\n",
        "# ---------- Authoritative exact names ----------\n",
        "# (Put brand/odd spellings here if needed; exact wins first, case-insensitive through normalization)\n",
        "EXACT_MAP: Dict[str, str] = {\n",
        "    # Personal Care\n",
        "    \"Toothbrush\": \"Personal Care\", \"Toothbrushes\": \"Personal Care\",\n",
        "    \"Toothpaste\": \"Personal Care\",\n",
        "    \"Shampoo\": \"Personal Care\", \"Conditioner\": \"Personal Care\",\n",
        "    \"Razor\": \"Personal Care\", \"Razors\": \"Personal Care\",\n",
        "    \"Deodorant\": \"Personal Care\",\n",
        "    \"Shower Gel\": \"Personal Care\", \"Hair Gel\": \"Personal Care\",\n",
        "    \"Shaving Cream\": \"Personal Care\",\n",
        "    \"Hand Sanitizer\": \"Personal Care\",\n",
        "    \"Feminine Hygiene Products\": \"Personal Care\",\n",
        "\n",
        "    # Dairy\n",
        "    \"Milk\": \"Dairy\", \"Cheese\": \"Dairy\", \"Butter\": \"Dairy\",\n",
        "    \"Yogurt\": \"Dairy\", \"Cream\": \"Dairy\", \"Ice Cream\": \"Dairy\",\n",
        "    \"Eggs\": \"Dairy\", \"Egg\": \"Dairy\",\n",
        "\n",
        "    # Bakery & Breakfast\n",
        "    \"Bread\": \"Bakery\",\n",
        "    \"Pancake Mix\": \"Bakery\",\n",
        "    \"Cake\": \"Bakery\",\n",
        "    \"Muffin\": \"Bakery\", \"Muffins\": \"Bakery\",\n",
        "    \"Bagel\": \"Bakery\", \"Bagels\": \"Bakery\",\n",
        "    \"Donut\": \"Bakery\", \"Donuts\": \"Bakery\",\n",
        "    \"Cereal\": \"Breakfast & Cereal\", \"Oatmeal\": \"Breakfast & Cereal\", \"Granola\": \"Breakfast & Cereal\",\n",
        "\n",
        "    # Produce (singular/plural covered)\n",
        "    \"Apple\": \"Produce\", \"Apples\": \"Produce\",\n",
        "    \"Banana\": \"Produce\", \"Bananas\": \"Produce\",\n",
        "    \"Orange\": \"Produce\", \"Oranges\": \"Produce\",\n",
        "    \"Tomato\": \"Produce\", \"Tomatoes\": \"Produce\",\n",
        "    \"Potato\": \"Produce\", \"Potatoes\": \"Produce\",\n",
        "    \"Onion\": \"Produce\", \"Onions\": \"Produce\",\n",
        "    \"Spinach\": \"Produce\", \"Lettuce\": \"Produce\",\n",
        "    \"Carrot\": \"Produce\", \"Carrots\": \"Produce\",\n",
        "    \"Cucumber\": \"Produce\", \"Cucumbers\": \"Produce\",\n",
        "\n",
        "    # Meat & Seafood\n",
        "    \"Chicken\": \"Meat\", \"Beef\": \"Meat\", \"Pork\": \"Meat\", \"Turkey\": \"Meat\", \"Lamb\": \"Meat\",\n",
        "    \"Fish\": \"Seafood\", \"Salmon\": \"Seafood\", \"Tuna\": \"Seafood\", \"Shrimp\": \"Seafood\",\n",
        "    \"Cod\": \"Seafood\", \"Trout\": \"Seafood\", \"Sardine\": \"Seafood\", \"Sardines\": \"Seafood\",\n",
        "\n",
        "    # Drinks & Snacks\n",
        "    \"Water\": \"Beverages\", \"Soda\": \"Beverages\", \"Cola\": \"Beverages\",\n",
        "    \"Juice\": \"Beverages\", \"Coffee\": \"Beverages\", \"Tea\": \"Beverages\",\n",
        "    \"Chips\": \"Snacks\", \"Chip\": \"Snacks\",\n",
        "    \"Cracker\": \"Snacks\", \"Crackers\": \"Snacks\",\n",
        "    \"Cookie\": \"Snacks\", \"Cookies\": \"Snacks\",\n",
        "    \"Candy\": \"Snacks\", \"Chocolate\": \"Snacks\",\n",
        "    \"Popcorn\": \"Snacks\", \"Nuts\": \"Snacks\", \"Trail Mix\": \"Snacks\", \"Granola Bar\": \"Snacks\",\n",
        "\n",
        "    # Pantry/Condiments\n",
        "    \"Ketchup\": \"Pantry/Condiments\", \"Mustard\": \"Pantry/Condiments\",\n",
        "    \"Mayonnaise\": \"Pantry/Condiments\", \"Mayo\": \"Pantry/Condiments\",\n",
        "    \"Bbq Sauce\": \"Pantry/Condiments\", \"BBQ Sauce\": \"Pantry/Condiments\",\n",
        "    \"Syrup\": \"Pantry/Condiments\",\n",
        "    \"Olive Oil\": \"Pantry/Condiments\", \"Vinegar\": \"Pantry/Condiments\",\n",
        "    \"Hot Sauce\": \"Pantry/Condiments\",\n",
        "    \"Honey\": \"Pantry/Condiments\",\n",
        "    \"Peanut Butter\": \"Pantry/Condiments\",\n",
        "    \"Pasta\": \"Pantry/Condiments\",\n",
        "\n",
        "    # Household & Cleaning\n",
        "    \"Dish Soap\": \"Household\", \"Soap\": \"Household\",\n",
        "    \"Detergent\": \"Household\", \"Laundry Detergent\": \"Household\",\n",
        "    \"Cleaner\": \"Household\", \"Cleaning Spray\": \"Household\",\n",
        "    \"Tissue\": \"Household\", \"Tissues\": \"Household\",\n",
        "    \"Sponge\": \"Household\", \"Sponges\": \"Household\",\n",
        "    \"Trash Can\": \"Household\", \"Trash Cans\": \"Household\",\n",
        "    \"Insect Repellent\": \"Household\", \"Air Freshener\": \"Household\",\n",
        "    \"Bath Towel\": \"Household\", \"Bath Towels\": \"Household\",\n",
        "\n",
        "    # Baby\n",
        "    \"Baby Wipes\": \"Baby\", \"Diaper\": \"Baby\", \"Diapers\": \"Baby\",\n",
        "\n",
        "    # Electronics/Hardware\n",
        "    \"Light Bulb\": \"Electronics/Hardware\", \"Light Bulbs\": \"Electronics/Hardware\",\n",
        "    \"Extension Cord\": \"Electronics/Hardware\", \"Extension Cords\": \"Electronics/Hardware\",\n",
        "    \"Power Strip\": \"Electronics/Hardware\", \"Power Strips\": \"Electronics/Hardware\",\n",
        "    \"Battery\": \"Electronics/Hardware\", \"Batteries\": \"Electronics/Hardware\",\n",
        "\n",
        "    # Home & Garden\n",
        "    \"Garden Hose\": \"Home & Garden\", \"Plant Fertilizer\": \"Home & Garden\",\n",
        "    \"Lawn Mower\": \"Home & Garden\", \"Broom\": \"Home & Garden\",\n",
        "    \"Dustpan\": \"Home & Garden\", \"Ironing Board\": \"Home & Garden\",\n",
        "}\n",
        "\n",
        "# ---------- Phrase rules (multi-word beats single-word) ----------\n",
        "PHRASE_RULES = [\n",
        "    (\"Dairy\",        r\"\\bice\\s*cream\\b\"),\n",
        "    (\"Personal Care\",r\"\\bshaving\\s*cream\\b\"),\n",
        "    (\"Bakery\",       r\"\\bpancake\\s*mix\\b\"),\n",
        "    (\"Pantry/Condiments\", r\"\\bbbq\\s*sauce\\b\"),\n",
        "    (\"Household\",    r\"\\bdish\\s*soap\\b\"),\n",
        "    (\"Household\",    r\"\\bcleaning\\s*spray\\b\"),\n",
        "    (\"Household\",    r\"\\binsect\\s*repellent\\b\"),\n",
        "    (\"Household\",    r\"\\btrash\\s*cans?\\b\"),\n",
        "    (\"Baby\",         r\"\\bbaby\\s*wipes?\\b\"),\n",
        "    (\"Electronics/Hardware\", r\"\\blight\\s*bulbs?\\b\"),\n",
        "    (\"Electronics/Hardware\", r\"\\bextension\\s*cords?\\b\"),\n",
        "    (\"Electronics/Hardware\", r\"\\bpower\\s*strips?\\b\"),\n",
        "    (\"Home & Garden\",r\"\\bgarden\\s*hose\\b\"),\n",
        "    (\"Home & Garden\",r\"\\bplant\\s*fertilizer\\b\"),\n",
        "    (\"Home & Garden\",r\"\\blawn\\s*mower\\b\"),\n",
        "    (\"Home & Garden\",r\"\\bair\\s*freshener\\b\"),\n",
        "    (\"Home & Garden\",r\"\\bbroom\\b\"),\n",
        "    (\"Home & Garden\",r\"\\bdustpan\\b\"),\n",
        "    (\"Home & Garden\",r\"\\bironing\\s*board\\b\"),\n",
        "    (\"Household\",    r\"\\bbath\\s*towels?\\b\"),\n",
        "]\n",
        "\n",
        "# ---------- Token-family rules (broad coverage) ----------\n",
        "FAMILY_KEYWORDS = {\n",
        "    \"Dairy\": [\"milk\",\"cheese\",\"butter\",\"yogurt\",\"cream\",\"egg\",\"eggs\",\"ice cream\"],\n",
        "    \"Bakery\": [\"bread\",\"cake\",\"donut\",\"pastry\",\"muffin\",\"bagel\",\"tortilla\",\"roll\",\"bun\",\"buns\"],\n",
        "    \"Breakfast & Cereal\": [\"cereal\",\"oatmeal\",\"granola\"],\n",
        "    \"Produce\": [\"apple\",\"apples\",\"banana\",\"bananas\",\"orange\",\"oranges\",\"tomato\",\"tomatoes\",\n",
        "                \"potato\",\"potatoes\",\"onion\",\"onions\",\"spinach\",\"lettuce\",\"carrot\",\"carrots\",\n",
        "                \"cucumber\",\"cucumbers\",\"broccoli\",\"pepper\",\"peppers\",\"avocado\",\"grape\",\"grapes\"],\n",
        "    \"Meat\": [\"chicken\",\"beef\",\"pork\",\"turkey\",\"lamb\",\"ham\",\"sausage\",\"bacon\"],\n",
        "    \"Seafood\": [\"fish\",\"salmon\",\"tuna\",\"shrimp\",\"cod\",\"trout\",\"sardine\",\"sardines\"],\n",
        "    \"Beverages\": [\"juice\",\"soda\",\"cola\",\"coffee\",\"tea\",\"water\",\"energy drink\",\"sports drink\",\"kombucha\"],\n",
        "    \"Snacks\": [\"chip\",\"chips\",\"cracker\",\"crackers\",\"cookie\",\"cookies\",\"candy\",\"chocolate\",\n",
        "               \"popcorn\",\"nuts\",\"trail mix\",\"granola bar\",\"pretzel\",\"pretzels\"],\n",
        "    \"Pantry/Condiments\": [\"ketchup\",\"mustard\",\"mayonnaise\",\"mayo\",\"syrup\",\"olive oil\",\"vinegar\",\n",
        "                          \"hot sauce\",\"honey\",\"peanut butter\",\"pasta\",\"rice\",\"flour\",\"sugar\",\"salt\",\n",
        "                          \"spice\",\"spices\",\"oil\"],\n",
        "    \"Household\": [\"dish soap\",\"soap\",\"detergent\",\"laundry detergent\",\"cleaner\",\"cleaning spray\",\n",
        "                  \"tissue\",\"tissues\",\"sponge\",\"sponges\",\"paper towel\",\"toilet paper\",\"foil\",\"wrap\",\n",
        "                  \"bag\",\"bags\",\"trash\",\"trash bag\",\"trash bags\",\"air freshener\"],\n",
        "    \"Personal Care\": [\"toothpaste\",\"toothbrush\",\"shampoo\",\"conditioner\",\"razor\",\"razors\",\n",
        "                      \"deodorant\",\"shower gel\",\"hair gel\",\"hand sanitizer\",\"lotion\",\"cream\",\"makeup\",\"cosmetic\"],\n",
        "    \"Baby\": [\"baby wipes\",\"diaper\",\"diapers\",\"formula\",\"baby food\",\"wipes\"],\n",
        "    \"Electronics/Hardware\": [\"light bulb\",\"bulb\",\"bulbs\",\"extension cord\",\"power strip\",\"battery\",\"batteries\"],\n",
        "    \"Home & Garden\": [\"garden hose\",\"fertilizer\",\"plant fertilizer\",\"lawn mower\",\"broom\",\"dustpan\",\n",
        "                      \"bath towel\",\"bath towels\",\"ironing board\",\"hose\",\"mower\",\"trowel\",\"rake\",\"shovel\"],\n",
        "}\n",
        "\n",
        "# Build compiled regex for families (vectorizable and robust)\n",
        "FAMILY_RULES: List[Tuple[str, re.Pattern]] = [\n",
        "    (cat, re.compile(r\"\\b(\" + \"|\".join(map(re.escape, kws)) + r\")\\b\", flags=re.IGNORECASE))\n",
        "    for cat, kws in FAMILY_KEYWORDS.items()\n",
        "]\n",
        "\n",
        "# ---------- Utilities ----------\n",
        "def normalize_item(x: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (x or \"\").strip()).title()\n",
        "\n",
        "def parse_product_list(cell):\n",
        "    if pd.isna(cell):\n",
        "        return []\n",
        "    s = str(cell).strip()\n",
        "    try:\n",
        "        val = ast.literal_eval(s)\n",
        "        if isinstance(val, list):\n",
        "            return [str(x) for x in val]\n",
        "        return [str(val)]\n",
        "    except Exception:\n",
        "        s = re.sub(r\"^\\[|\\]$\", \"\", s)\n",
        "        parts = [p.strip(\" '\\\"\\t\\r\\n\") for p in s.split(\",\")]\n",
        "        return [p for p in parts if p]\n",
        "\n",
        "def detect_product_column(columns: Iterable[str]) -> str:\n",
        "    for c in columns:\n",
        "        if c.strip().lower() in PRODUCT_COL_CANDIDATES:\n",
        "            return c\n",
        "    return list(columns)[0]\n",
        "\n",
        "def categorize(name: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Returns (category, rule_type) where rule_type in {'exact','phrase','family','headnoun','last_resort'}\n",
        "    \"\"\"\n",
        "    disp = normalize_item(name)\n",
        "    low  = disp.lower()\n",
        "\n",
        "    # 1) exact (case-sensitive after normalize for consistent keys)\n",
        "    if disp in EXACT_MAP:\n",
        "        return EXACT_MAP[disp], \"exact\"\n",
        "    # trivial plural/singular flips\n",
        "    if disp.endswith(\"s\") and disp[:-1] in EXACT_MAP:\n",
        "        return EXACT_MAP[disp[:-1]], \"exact\"\n",
        "    if f\"{disp}s\" in EXACT_MAP:\n",
        "        return EXACT_MAP[f\"{disp}s\"], \"exact\"\n",
        "\n",
        "    # 2) phrase rules\n",
        "    for cat, rx in PHRASE_RULES:\n",
        "        if re.search(rx, low):\n",
        "            return cat, \"phrase\"\n",
        "\n",
        "    # 3) family rules\n",
        "    for cat, rx in FAMILY_RULES:\n",
        "        if rx.search(low):\n",
        "            return cat, \"family\"\n",
        "\n",
        "    # 4) head-noun heuristic:\n",
        "    #    Use the last token as the head noun (e.g., \"Bath Towels\" -> \"Towels\", \"Trash Bags\" -> \"Bags\")\n",
        "    tokens = [t for t in re.split(r\"[^a-z0-9]+\", low) if t]\n",
        "    if tokens:\n",
        "        head = tokens[-1]\n",
        "        head_map = {\n",
        "            # map common head nouns\n",
        "            \"towel\": \"Household\", \"towels\": \"Household\",\n",
        "            \"bag\": \"Household\", \"bags\": \"Household\",\n",
        "            \"bulb\": \"Electronics/Hardware\", \"bulbs\": \"Electronics/Hardware\",\n",
        "            \"cord\": \"Electronics/Hardware\", \"cords\": \"Electronics/Hardware\",\n",
        "            \"strip\": \"Electronics/Hardware\", \"strips\": \"Electronics/Hardware\",\n",
        "            \"hose\": \"Home & Garden\",\n",
        "            \"fertilizer\": \"Home & Garden\",\n",
        "            \"mower\": \"Home & Garden\",\n",
        "            \"broom\": \"Home & Garden\",\n",
        "            \"dustpan\": \"Home & Garden\",\n",
        "            \"tissue\": \"Household\", \"tissues\": \"Household\",\n",
        "            \"sponge\": \"Household\", \"sponges\": \"Household\",\n",
        "            \"soap\": \"Household\",\n",
        "            \"detergent\": \"Household\",\n",
        "            \"ketchup\": \"Pantry/Condiments\", \"mustard\": \"Pantry/Condiments\",\n",
        "            \"mayonnaise\": \"Pantry/Condiments\", \"mayo\": \"Pantry/Condiments\",\n",
        "            \"syrup\": \"Pantry/Condiments\",\n",
        "            \"pasta\": \"Pantry/Condiments\",\n",
        "            \"water\": \"Beverages\", \"soda\": \"Beverages\", \"coffee\": \"Beverages\", \"tea\": \"Beverages\",\n",
        "            \"chips\": \"Snacks\", \"cracker\": \"Snacks\", \"crackers\": \"Snacks\",\n",
        "            \"cookies\": \"Snacks\", \"cookie\": \"Snacks\", \"candy\": \"Snacks\", \"chocolate\": \"Snacks\",\n",
        "            \"bread\": \"Bakery\", \"cereal\": \"Breakfast & Cereal\",\n",
        "            \"apple\": \"Produce\", \"apples\": \"Produce\", \"tomatoes\": \"Produce\", \"tomato\": \"Produce\",\n",
        "            \"potatoes\": \"Produce\", \"potato\": \"Produce\", \"onions\": \"Produce\", \"onion\": \"Produce\",\n",
        "            \"spinach\": \"Produce\", \"lettuce\": \"Produce\", \"carrots\": \"Produce\", \"carrot\": \"Produce\",\n",
        "            \"salmon\": \"Seafood\", \"tuna\": \"Seafood\", \"shrimp\": \"Seafood\", \"fish\": \"Seafood\",\n",
        "            \"milk\": \"Dairy\", \"cheese\": \"Dairy\", \"butter\": \"Dairy\", \"yogurt\": \"Dairy\", \"eggs\": \"Dairy\",\n",
        "            \"toothbrush\": \"Personal Care\", \"toothpaste\": \"Personal Care\",\n",
        "            \"shampoo\": \"Personal Care\", \"conditioner\": \"Personal Care\",\n",
        "            \"razor\": \"Personal Care\", \"razors\": \"Personal Care\", \"deodorant\": \"Personal Care\",\n",
        "            \"gel\": \"Personal Care\", \"sanitizer\": \"Personal Care\",\n",
        "        }\n",
        "        if head in head_map:\n",
        "            return head_map[head], \"headnoun\"\n",
        "\n",
        "    # 5) last resort: assign to a sensible broad bucket instead of \"Other\"\n",
        "    # If we reach here, prefer Household for generic goods.\n",
        "    return \"Household\", \"last_resort\"\n",
        "\n",
        "\n",
        "def process_chunk(chunk: pd.DataFrame, product_col: str) -> pd.DataFrame:\n",
        "    # Parse list column and explode to one item per row\n",
        "    chunk = chunk.copy()\n",
        "    chunk[\"_items_list\"] = chunk[product_col].apply(parse_product_list)\n",
        "    ex = chunk.explode(\"_items_list\", ignore_index=True).rename(columns={\"_items_list\": \"product_item\"})\n",
        "    ex[\"product_item\"] = ex[\"product_item\"].fillna(\"\").astype(str).str.strip()\n",
        "    ex = ex[ex[\"product_item\"] != \"\"]\n",
        "    ex[\"product_item_clean\"] = ex[\"product_item\"].apply(normalize_item)\n",
        "\n",
        "    # Categorize\n",
        "    cats, hows = zip(*ex[\"product_item_clean\"].map(categorize))\n",
        "    ex[\"product_category\"] = list(cats)\n",
        "    ex[\"categorization_method\"] = list(hows)\n",
        "    return ex\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Detect product column from a small sample\n",
        "    head = pd.read_csv(INPUT, nrows=20)\n",
        "    product_col = detect_product_column(head.columns)\n",
        "\n",
        "    first = True\n",
        "    for i, chunk in enumerate(pd.read_csv(INPUT, chunksize=CHUNK_SIZE), start=1):\n",
        "        out = process_chunk(chunk, product_col)\n",
        "        out.to_csv(OUTPUT, index=False, mode=\"w\" if first else \"a\", header=first)\n",
        "        first = False\n",
        "        print(f\"[Chunk {i}] wrote {len(out):,} rows\")\n",
        "\n",
        "    # Build mapping & verify no uncategorized remain\n",
        "    full = pd.read_csv(OUTPUT, usecols=[\"product_item_clean\", \"product_category\", \"categorization_method\"])\n",
        "    # Produce unique mapping\n",
        "    mapping = (full\n",
        "               .drop_duplicates(subset=[\"product_item_clean\"])\n",
        "               .sort_values(\"product_item_clean\"))\n",
        "    mapping.to_csv(MAPCSV, index=False)\n",
        "\n",
        "    # Any non-categorized? (There shouldn't be — last_resort handles stragglers)\n",
        "    uncertain = mapping.loc[mapping[\"product_category\"].eq(\"Other\") |\n",
        "                            mapping[\"categorization_method\"].isin([\"fallback\"]), \"product_item_clean\"]\n",
        "    # But we still save a file for inspection:\n",
        "    pd.DataFrame({\"product_item_clean\": sorted(set(uncertain.tolist()))}).to_csv(UNCERT, index=False)\n",
        "\n",
        "    # Hard assert: zero unassigned \"Other\"\n",
        "    # (If you want to allow a few for manual review, comment this assert out.)\n",
        "    assert mapping.loc[mapping[\"product_category\"].eq(\"Other\")].empty, \\\n",
        "        \"There are still 'Other' items; expand EXACT_MAP / FAMILY_KEYWORDS / headnoun map.\"\n",
        "\n",
        "    print(\"\\nDone. Files written:\")\n",
        "    print(f\"  - {OUTPUT}\")\n",
        "    print(f\"  - {MAPCSV}\")\n",
        "    print(f\"  - {UNCERT} (should be empty)\")\n",
        "    print(\"\\nCategory breakdown (unique products):\")\n",
        "    print(mapping[\"product_category\"].value_counts().sort_values(ascending=False).to_string())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB1f1rEjy_ZT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
